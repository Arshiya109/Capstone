{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3NCqcpioOSXU1ZtH7uYpm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arshiya109/Fundamentals-of-Deep-Learning/blob/main/RNN's_in_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Recurrent Neural Network**\n",
        "\n",
        "We will explore the concept of the Recurrent Neural Network.\n",
        "\n",
        "Recurrent Neural Networks (RNNs) are a type of neural network designed for processing sequences of data. Unlike traditional neural networks, which assume that inputs are independent of each other, RNNs consider the order and dependencies between elements in a sequence. This makes them particularly useful for tasks like language modeling, speech recognition, and time series prediction.\n",
        "\n",
        "In an RNN, information cycles through a loop, allowing it to maintain a memory of previous inputs and make decisions based on the context of the entire sequence. However, RNNs can struggle with long-term dependencies, which has led to the development of more advanced architectures like LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Unit) networks that better handle these challenges.\n",
        "\n",
        "We will take an program which will help to understand how the RNNs works.This program will cover the basic structure and steps involved in building and training an RNN."
      ],
      "metadata": {
        "id": "irQINaQTaBGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importing Libraries\n",
        "Firstly , we need to import the necessary libraries in the program. We are going to prefer the PyTorch Library."
      ],
      "metadata": {
        "id": "6-HtY8pscPEr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f23KZ5TpZr8t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Creating a Simple Dataset\n",
        "\n",
        "For this example, we are going to create a simple dataset. We'll generate some dummy sequential data for training and testing the RNN."
      ],
      "metadata": {
        "id": "Oa7Np8NpconV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, data_size=1000, seq_len=10):\n",
        "        self.data_size = data_size\n",
        "        self.seq_len = seq_len\n",
        "        self.data = torch.randn(data_size, seq_len, 1)\n",
        "        self.labels = torch.randint(0, 2, (data_size,))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "train_dataset = SimpleDataset(data_size=1000, seq_len=10)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = SimpleDataset(data_size=200, seq_len=10)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Function to visualize some samples from the dataset\n",
        "def visualize_samples(loader, num_samples=5):\n",
        "    samples = []\n",
        "    labels = []\n",
        "\n",
        "    for data, label in loader:\n",
        "        samples.append(data)\n",
        "        labels.append(label)\n",
        "        if len(samples) >= num_samples:\n",
        "            break\n",
        "\n",
        "    samples = torch.cat(samples, dim=0)[:num_samples]\n",
        "    labels = torch.cat(labels, dim=0)[:num_samples]\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
        "    for i in range(num_samples):\n",
        "        # Reshape the data to a 2D array for visualization\n",
        "        image = samples[i].numpy().squeeze().reshape(2, 5)\n",
        "        axes[i].imshow(image, cmap='gray')\n",
        "        axes[i].set_title(f'Label: {labels[i].item()}')\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Visualize some samples from the train loader\n",
        "visualize_samples(train_loader, num_samples=5)\n"
      ],
      "metadata": {
        "id": "92HS4P3zc4Up",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "1d033f7a-0a7c-4b47-f806-fa019fd2cb90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Defining the RNN Model\n",
        "We are going to define a simple RNN model."
      ],
      "metadata": {
        "id": "dBb8aLQ4c7GZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out[:, -1, :]  # Take the last output of the sequence\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "input_size = 1\n",
        "hidden_size = 16\n",
        "output_size = 2\n",
        "num_layers = 1\n",
        "\n",
        "net = SimpleRNN(input_size, hidden_size, output_size, num_layers).to(device)\n",
        "print(net)"
      ],
      "metadata": {
        "id": "cAnw9mqsdJ5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c273524-7bc4-499e-9b71-c43e225cb158"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "SimpleRNN(\n",
            "  (rnn): RNN(1, 16, batch_first=True)\n",
            "  (fc): Linear(in_features=16, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Defining the Loss Function and Optimizer\n",
        "\n",
        "We are going to specify the loss function and the optimizer for this Model."
      ],
      "metadata": {
        "id": "Y-G02DvJdORk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "print(criterion)\n",
        "print(optimizer)"
      ],
      "metadata": {
        "id": "89x-12hjdXr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ad7f41-3cb3-4256-d689-151629d9b101"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CrossEntropyLoss()\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Training the Model\n",
        "We are training the model on the training data."
      ],
      "metadata": {
        "id": "KYfTc7efdcFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        # Move tensors to the correct device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 10:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV0lZmqRdnYm",
        "outputId": "17079262-c3b5-4f3d-e7ec-5fd351a806ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 10, Loss: 0.708\n",
            "Epoch 1, Batch 20, Loss: 0.692\n",
            "Epoch 1, Batch 30, Loss: 0.691\n",
            "Epoch 2, Batch 10, Loss: 0.699\n",
            "Epoch 2, Batch 20, Loss: 0.692\n",
            "Epoch 2, Batch 30, Loss: 0.692\n",
            "Epoch 3, Batch 10, Loss: 0.690\n",
            "Epoch 3, Batch 20, Loss: 0.695\n",
            "Epoch 3, Batch 30, Loss: 0.694\n",
            "Epoch 4, Batch 10, Loss: 0.694\n",
            "Epoch 4, Batch 20, Loss: 0.691\n",
            "Epoch 4, Batch 30, Loss: 0.693\n",
            "Epoch 5, Batch 10, Loss: 0.692\n",
            "Epoch 5, Batch 20, Loss: 0.693\n",
            "Epoch 5, Batch 30, Loss: 0.694\n",
            "Epoch 6, Batch 10, Loss: 0.693\n",
            "Epoch 6, Batch 20, Loss: 0.691\n",
            "Epoch 6, Batch 30, Loss: 0.692\n",
            "Epoch 7, Batch 10, Loss: 0.695\n",
            "Epoch 7, Batch 20, Loss: 0.692\n",
            "Epoch 7, Batch 30, Loss: 0.691\n",
            "Epoch 8, Batch 10, Loss: 0.691\n",
            "Epoch 8, Batch 20, Loss: 0.693\n",
            "Epoch 8, Batch 30, Loss: 0.692\n",
            "Epoch 9, Batch 10, Loss: 0.689\n",
            "Epoch 9, Batch 20, Loss: 0.692\n",
            "Epoch 9, Batch 30, Loss: 0.693\n",
            "Epoch 10, Batch 10, Loss: 0.690\n",
            "Epoch 10, Batch 20, Loss: 0.693\n",
            "Epoch 10, Batch 30, Loss: 0.694\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Evaluating the Model\n",
        "\n",
        "We are going to evaluate the model on the test data."
      ],
      "metadata": {
        "id": "5BfnVbUXeknr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the test data: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIL1qfMCevu4",
        "outputId": "a1188ba3-9418-43b5-efe2-dc07b894f677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test data: 52.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CONCLUSION:\n",
        "\n",
        "In overall it concludes that in  RNN with PyTorch involves several key steps. Firstly, we import the necessary libraries. Then, we create a simple dataset with dummy sequential data. Next, we define the RNN model architecture. After that, we set up the loss function and optimizer to guide the learning process. We then train the model using the training data and finally evaluate its performance on new data. This step-by-step approach provides a clear and basic understanding of building and using an RNN in PyTorch."
      ],
      "metadata": {
        "id": "tieBC8kFfCGZ"
      }
    }
  ]
}