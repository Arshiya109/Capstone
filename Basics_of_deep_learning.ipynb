{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEeyfRQ3xSk1yY0O7G8rzf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arshiya109/Fundamentals-of-Deep-Learning/blob/main/Basics_of_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Learning Basic**\n",
        "\n",
        "Here we will start with the Fundamentals of the deep learning.\n",
        "\n",
        "Firstly we will understand \"What is mean bydeep learning?\".\n",
        "\n",
        "Deep learning is a subset of machine learning that employs artificial neural networks to learn from data in a manner similar to how the human brain operates. It is termed \"deep\" because these neural networks contain multiple layers, allowing the model to learn progressively more complex features from the data.\n",
        "\n",
        "To grasp this concept, we'll begin with a basic example of image classification. Suppose we want to train a deep learning model to classify images of animals. We would provide the model with a large dataset of labeled animal images, such as cats, dogs, and horses. This process involves several methods and techniques that we will cover."
      ],
      "metadata": {
        "id": "PaUC-B7Y-_1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Importing the Necessary Libraries\n",
        "\n",
        "Now we will import the required liabraries."
      ],
      "metadata": {
        "id": "NnxOdJi2_vem"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OkDVLb7t--pF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we're using the CIFAR-10 dataset in which it contains 60,000 (32x32) color images in 10 classes, such as dogs, cats, airplanes and many more."
      ],
      "metadata": {
        "id": "Wedn38yR_6NX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Defining the Deep Learning Model\n",
        "\n",
        "Now, we'll define a simple neural network with three fully connected layers. The forward() method defines the forward pass of the network.\n"
      ],
      "metadata": {
        "id": "5F_Kguc2A2Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "oUEGSsAlMh7w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Loading and Preprocessing the Data\n",
        "\n",
        "We use the torchvision.datasets.MNIST module to download and load the MNIST dataset. We apply a transformation to normalize the input images.\n",
        "\n",
        "Here we are using the nn.CrossEntropyLoss as the loss function and optim.SGD as the optimizer for our MNIST Dataset."
      ],
      "metadata": {
        "id": "ay5pJUR6ATFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "def visualize_samples(loader, num_samples=5):\n",
        "    dataiter = iter(loader)\n",
        "    images, labels = next(dataiter)\n",
        "\n",
        "    images = images[:num_samples]\n",
        "    labels = labels[:num_samples]\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
        "    for i in range(num_samples):\n",
        "        image = images[i].numpy().squeeze()\n",
        "        axes[i].imshow(image, cmap='gray')\n",
        "        axes[i].set_title(f'Label: {labels[i].item()}')\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Visualize some samples from the train loader\n",
        "visualize_samples(trainloader, num_samples=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "yCavlgITAn4U",
        "outputId": "325f9b8e-9743-4a10-8413-c1d055bd36bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Training the Model\n",
        "\n",
        "This step is an important aspect Deep learning. Here we are training the model for 10 epochs, using a batch size of the 64. In each iteration, we forward the input through the network, computing the loss, backpropagating the gradients, and updating the model parameters."
      ],
      "metadata": {
        "id": "cH94aqtcB2XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSFXmSfQCjR5",
        "outputId": "4e5e1499-0e73-4a90-8466-1942e7db4f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 2.216\n",
            "[1,   200] loss: 1.829\n",
            "[1,   300] loss: 1.186\n",
            "[1,   400] loss: 0.754\n",
            "[1,   500] loss: 0.585\n",
            "[1,   600] loss: 0.474\n",
            "[1,   700] loss: 0.442\n",
            "[1,   800] loss: 0.398\n",
            "[1,   900] loss: 0.384\n",
            "[2,   100] loss: 0.353\n",
            "[2,   200] loss: 0.336\n",
            "[2,   300] loss: 0.334\n",
            "[2,   400] loss: 0.318\n",
            "[2,   500] loss: 0.322\n",
            "[2,   600] loss: 0.299\n",
            "[2,   700] loss: 0.307\n",
            "[2,   800] loss: 0.289\n",
            "[2,   900] loss: 0.294\n",
            "[3,   100] loss: 0.289\n",
            "[3,   200] loss: 0.275\n",
            "[3,   300] loss: 0.270\n",
            "[3,   400] loss: 0.254\n",
            "[3,   500] loss: 0.252\n",
            "[3,   600] loss: 0.258\n",
            "[3,   700] loss: 0.244\n",
            "[3,   800] loss: 0.253\n",
            "[3,   900] loss: 0.240\n",
            "[4,   100] loss: 0.236\n",
            "[4,   200] loss: 0.225\n",
            "[4,   300] loss: 0.229\n",
            "[4,   400] loss: 0.223\n",
            "[4,   500] loss: 0.216\n",
            "[4,   600] loss: 0.208\n",
            "[4,   700] loss: 0.203\n",
            "[4,   800] loss: 0.224\n",
            "[4,   900] loss: 0.212\n",
            "[5,   100] loss: 0.205\n",
            "[5,   200] loss: 0.200\n",
            "[5,   300] loss: 0.191\n",
            "[5,   400] loss: 0.192\n",
            "[5,   500] loss: 0.207\n",
            "[5,   600] loss: 0.198\n",
            "[5,   700] loss: 0.176\n",
            "[5,   800] loss: 0.172\n",
            "[5,   900] loss: 0.173\n",
            "[6,   100] loss: 0.173\n",
            "[6,   200] loss: 0.157\n",
            "[6,   300] loss: 0.179\n",
            "[6,   400] loss: 0.159\n",
            "[6,   500] loss: 0.178\n",
            "[6,   600] loss: 0.174\n",
            "[6,   700] loss: 0.159\n",
            "[6,   800] loss: 0.166\n",
            "[6,   900] loss: 0.161\n",
            "[7,   100] loss: 0.146\n",
            "[7,   200] loss: 0.148\n",
            "[7,   300] loss: 0.153\n",
            "[7,   400] loss: 0.141\n",
            "[7,   500] loss: 0.157\n",
            "[7,   600] loss: 0.149\n",
            "[7,   700] loss: 0.152\n",
            "[7,   800] loss: 0.146\n",
            "[7,   900] loss: 0.150\n",
            "[8,   100] loss: 0.141\n",
            "[8,   200] loss: 0.133\n",
            "[8,   300] loss: 0.133\n",
            "[8,   400] loss: 0.142\n",
            "[8,   500] loss: 0.138\n",
            "[8,   600] loss: 0.130\n",
            "[8,   700] loss: 0.122\n",
            "[8,   800] loss: 0.131\n",
            "[8,   900] loss: 0.138\n",
            "[9,   100] loss: 0.125\n",
            "[9,   200] loss: 0.118\n",
            "[9,   300] loss: 0.133\n",
            "[9,   400] loss: 0.121\n",
            "[9,   500] loss: 0.118\n",
            "[9,   600] loss: 0.121\n",
            "[9,   700] loss: 0.118\n",
            "[9,   800] loss: 0.127\n",
            "[9,   900] loss: 0.115\n",
            "[10,   100] loss: 0.105\n",
            "[10,   200] loss: 0.124\n",
            "[10,   300] loss: 0.112\n",
            "[10,   400] loss: 0.120\n",
            "[10,   500] loss: 0.105\n",
            "[10,   600] loss: 0.112\n",
            "[10,   700] loss: 0.106\n",
            "[10,   800] loss: 0.114\n",
            "[10,   900] loss: 0.100\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Evaluating the Model\n",
        "\n",
        "After training the dataset, we can evaluate the model's performance based on the test set. We are computing the overall accuracy of the network on the 10,000 test images.\n",
        "\n"
      ],
      "metadata": {
        "id": "yr0W10HiCt-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT9vsVlQDFAE",
        "outputId": "bb9e8497-44e9-40e0-ffc0-db3c3b0d78bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 96 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CONCLUSION:\n",
        "\n",
        "This simple example provides a solid foundation for understanding the basic structure and workflow of training a deep learning model using PyTorch. It covers the essential components, such as defining the network architecture, loading and preprocessing data, setting up the training process, and evaluating the model's performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "oplb5oWeDmq5"
      }
    }
  ]
}